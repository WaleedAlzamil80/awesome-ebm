# Awesome Energy Based Model/Learning (Awesome-EBM)
[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome#readme)
> A comprehensive list of awesome energy based learning papers and materials.

## Table of Contents
- [Workshops & Symposiums](#workshops--symposiums)
- [Papers](#papers)
    - [2021](#2021)
    - [2020](#2020)
    - [2019](#2019)
    - [2017 ~ 2018](#2017--2018)
    - [2013 ~ 2016](#2013--2016)
    - [2007 ~ 2012](#2007--2012)
    - [Early papers (Before 2006)](#early-papers-before-2006)   
- [Materials](#materials)


## Workshops & Symposiums

- [ ] [EBM Workshop at ICLR 2021.](https://sites.google.com/view/ebm-workshop-iclr2021/home)


## Papers

### 2021

- [ ] [2021: Song, Y., & Kingma, D. P.  \
How to Train Your Energy-Based Models. arXiv preprint arXiv:2101.03288, 2021. ](https://arxiv.org/pdf/2101.03288.pdf)

- [ ] [Liu, M., Yan, K., Oztekin, B., & Ji, S. (2021).  \
GraphEBM: Molecular Graph Generation with Energy-Based Models. arXiv preprint arXiv:2102.00546.](https://arxiv.org/abs/2102.00546)

- [ ] [Wu, H., Esmaeili, B., Wick, M., Tristan, J. B., & van de Meent, J. W. \
Conjugate Energy-Based Models.](https://openreview.net/pdf?id=4k58RmAD02)

- [ ] [Zheng, Z., Xie, J., & Li, P. \
Patchwise Generative ConvNet: Training Energy-Based Models from a Single Natural Image for Internal Learning..](http://www.stat.ucla.edu/~jxie/personalpage_file/publications/internal_EBM.pdf)







### 2020

- [ ] [2020: Gustafsson, F. K., Danelljan, M., Timofte, R., and Schön, T. B. \
How to Train Your Energy-Based Model for Regression. arXiv preprint arXiv:2005.01698, 2020.](https://arxiv.org/pdf/2005.01698.pdf)

- [ ] [2020: Niu, C., Song, Y., Song, J., Zhao, S., Grover, A., and Ermon, S. \
Permutation invariant graph generation via score-Based generative modeling. In International Conference on Artificial Intelligence and Statistics (pp. 4474-4484). PMLR, 2020.](https://arxiv.org/pdf/2003.00638.pdf) *[[code]](https://github.com/ermongroup/GraphScoreMatching)*

- [ ] [2020: Liu, H., and Abbeel, P. \
Hybrid discriminative-generative training via contrastive learning. arXiv preprint arXiv:2007.09070, 2020.](https://arxiv.org/pdf/2007.09070.pdf)

- [ ] [2020: Arbel, Michael, Zhou, Liang, and  Gretton,  Arthur.  \
 Generalized energy based models.arXiv e-prints,pp. arXiv–2003, 2020.](https://arxiv.org/pdf/2003.05033.pdf)

- [ ] [2020: Song,  Yang,  Sohl-Dickstein,  Jascha,  Kingma,  Diederik P, Kumar,  Abhishek,  Ermon,  Ste-fano, and Poole, Ben.   \
Score-based generative modeling through stochastic differential equations.arXiv preprint arXiv:2011.13456, 2020.](https://arxiv.org/pdf/2011.13456.pdf)

- [ ] [2020: Song, Yang, and Stefano Ermon.  \
Improved techniques for training score-based generative models." arXiv preprint arXiv:2006.09011 (2020).](https://arxiv.org/abs/2006.09011)

- [ ] [2020: Gao, Ruiqi, et al. \
"Flow contrastive estimation of energy-based models." Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020.](https://openaccess.thecvf.com/content_CVPR_2020/papers/Gao_Flow_Contrastive_Estimation_of_Energy-Based_Models_CVPR_2020_paper.pdf)

- [ ] [2020: Khemakhem, Ilyes, et al. \
"ICE-BeeM: Identifiable Conditional Energy-Based Deep Models Based on Nonlinear ICA." Advances in Neural Information Processing Systems 33 (2020).](https://arxiv.org/abs/2002.11537) *[[code]](https://github.com/ilkhem/icebeem)*

- [ ] [2020: Cotta, L., Teixeira, C. H., Swami, A., & Ribeiro, B. (2020). \
 Unsupervised Joint $k$-node Graph Representations with Compositional Energy-Based Models. arXiv preprint arXiv:2010.04259.](https://arxiv.org/abs/2010.04259)


- [ ] [2020:  Pang, B., Han, T., Nijkamp, E., Zhu, S. C., & Wu, Y. N. (2020).\
Learning latent space energy-based prior model. arXiv preprint arXiv:2006.08205.](https://arxiv.org/abs/2006.08205)



- [ ] [Liu, W., Wang, X., Owens, J. D., & Li, Y. (2020).\
 Energy-based Out-of-distribution Detection. arXiv preprint arXiv:2010.03759.](https://arxiv.org/abs/2010.03759)

- [ ] [Nijkamp, E., Hill, M., Han, T., Zhu, S. C., & Wu, Y. N. (2020, April). \
    On the anatomy of mcmc-based maximum likelihood learning of energy-based models. In Proceedings of the AAAI Conference on Artificial Intelligence (Vol. 34, No. 04, pp. 5272-5280).](https://ojs.aaai.org/index.php/AAAI/article/view/5973)





### 2019

- [ ] [2019: Song, Y., and Ermon, S.  \
Generative Modeling by Estimating Gradients of the Data Distribution. In Proceedings of the 33rd Annual Conference on Neural Information Processing Systems, 2019.](https://arxiv.org/pdf/1907.05600.pdf) *[[code]](https://github.com/ermongroup/ncsn)*

- [ ] [2019: Grathwohl, W., Wang, K. C., Jacobsen, J. H., Duvenaud, D., Norouzi, M., & Swersky, K.  \
Your classifier is secretly an energy based model and you should treat it like one. arXiv preprint arXiv:1912.03263, 2019.](https://arxiv.org/pdf/1912.03263.pdf)  *[[code]](https://github.com/wgrathwohl/JEM)*

- [ ] [2019: Bian, Y., Buhmann, J., & Krause, A. \
 Optimal continuous dr-submodular maximization and applications to provable mean field inference. In International Conference on Machine Learning (pp. 644-653). PMLR.](http://proceedings.mlr.press/v97/bian19a.html)  *[[code]](https://github.com/bianan/optimal-dr-submodular-max)*

- [ ] [2019: Du, Yilun, and Igor Mordatch. \
 Implicit generation and modeling with energy based models. (2019).](https://arxiv.org/pdf/1903.08689.pdf)

- [ ] [Nijkamp, E., Hill, M., Zhu, S. C., & Wu, Y. N. (2019). \
  Learning non-convergent non-persistent short-run MCMC toward energy-based model. arXiv preprint arXiv:1904.09770.](https://arxiv.org/abs/1904.09770)







### 2017 ~ 2018

- [ ] [Mordatch, I. (2018). \
 Concept learning with energy-based models. arXiv preprint arXiv:1811.02486.](https://arxiv.org/abs/1811.02486)  *[[blog]](https://openai.com/blog/learning-concepts-with-energy-functions/)*


- [ ] [Xie, J., Lu, Y., Gao, R., Zhu, S. C., & Wu, Y. N. (2018). \
 Cooperative training of descriptor and generator networks. IEEE transactions on pattern analysis and machine intelligence, 42(1), 27-45.](https://arxiv.org/abs/1609.09408) *[[code]](https://github.com/jianwen-xie/CoopNets)*

- [ ] [Gao, R., Lu, Y., Zhou, J., Zhu, S. C., & Wu, Y. N. (2018). \
 Learning generative convnets via multi-grid modeling and sampling. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (pp. 9155-9164).](https://openaccess.thecvf.com/content_cvpr_2018/papers/Gao_Learning_Generative_ConvNets_CVPR_2018_paper.pdf) *[[code]](https://github.com/prateekm08/Multigrid-PyTorch)*




### 2013 ~ 2016


- [ ] [2016: Zhao, J., Mathieu, M., & LeCun, Y. (2016). \
  Energy-based generative adversarial network. arXiv preprint arXiv:1609.03126.](https://arxiv.org/abs/1609.03126)


- [ ] [Xie, J., Lu, Y., Zhu, S. C., & Wu, Y. (2016, June). \
A theory of generative convnet. In International Conference on Machine Learning (pp. 2635-2644). PMLR.](http://proceedings.mlr.press/v48/xiec16.html)

### 2007 ~ 2012

- [ ] [2012: Parry, Matthew, Dawid, A Philip, Lauritzen, Steffen, et al.  \
 Proper local scoring rules.Annals of Statistics, 40(1):561–592, 2012.](http://www.stats.ox.ac.uk/~steffen/papers/AOS971.pdf)


 - [ ] [Welling, M., & Teh, Y. W. (2011).\
  Bayesian learning via stochastic gradient Langevin dynamics. In Proceedings of the 28th international conference on machine learning (ICML-11) (pp. 681-688).](http://www.stats.ox.ac.uk/~steffen/papers/AOS971.pdf)




### Early papers (Before 2006)


- [ ] [2006: LeCun,  Yann,  Chopra,  Sumit,  Hadsell,  Raia,  Ranzato,  M,  and  Huang,  F.   \
A  tutorial  on energy-based learning. Predicting structured data, 1(0), 2006](http://yann.lecun.com/exdb/publis/pdf/lecun-06.pdf)


- [ ] [Hinton, G. E., Osindero, S., & Teh, Y. W. (2006). \
 A fast learning algorithm for deep belief nets. Neural computation, 18(7), 1527-1554.](https://direct.mit.edu/neco/article/18/7/1527/7065/A-Fast-Learning-Algorithm-for-Deep-Belief-Nets)


- [ ] [Welling, M., Rosen-Zvi, M., & Hinton, G. E. (2004, December). \
Exponential Family Harmoniums with an Application to Information Retrieval. In Nips (Vol. 4, pp. 1481-1488).](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.86.5757&rep=rep1&type=pdf)


- [ ] [Smolensky, P. (1986).  \
Information processing in dynamical systems: Foundations of harmony theory. Colorado Univ at Boulder Dept of Computer Science.](https://apps.dtic.mil/sti/citations/ADA620727)


- [ ] [1957a: Jaynes, Edwin T. \
Information theory and statistical mechanics.Physical review, 106(4):620,1957a](https://journals.aps.org/pr/abstract/10.1103/PhysRev.106.620)

- [ ] [1957b: Jaynes, Edwin T.   \
Information theory and statistical mechanics. ii. Physical review, 108(2):171, 1957b.](https://journals.aps.org/pr/abstract/10.1103/PhysRev.108.171)


## Materials


- [ ] [2020 Youtube video: Stefano Ermon   \
Generative Modeling by Estimating Gradients of the Data Distribution](https://www.youtube.com/watch?v=8TcNXi3A5DI&t=3409s)
